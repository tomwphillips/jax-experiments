{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN7h11+GFYXVCyW2MUvQTAG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomwphillips/jax-experiments/blob/master/MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmYf8gbBSDG7",
        "colab_type": "text"
      },
      "source": [
        "# MNIST classification with JAX\n",
        "[JAX](https://github.com/google/jax) gives you automatic differentiation and GPU/TPU support for Python and numpy transformations.\n",
        "\n",
        "Here I've had a play around with it (largely following the [MNIST example](https://github.com/google/jax/blob/master/docs/notebooks/neural_network_with_tfds_data.ipynb) in the JAX repo). `jax.vmap` vectorizes numpy operations (for batching predictions) and `jax.grad` takes the derivative of the loss function with respect to the parameters.\n",
        "\n",
        "Pretty neat. I like how lightweight it is compared to TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvDGtOYEIlMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import jax\n",
        "import jax.numpy as np\n",
        "import jax.random as random\n",
        "from jax.scipy.special import logsumexp\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hl0NIwvnPSB",
        "colab_type": "text"
      },
      "source": [
        "# Load mnist"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YceY972aImEO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist, info = tfds.load('mnist', batch_size=-1, with_info=True)\n",
        "mnist = tfds.as_numpy(mnist)\n",
        "train, test = mnist['train'], mnist['test']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RleOYn6RLwR4",
        "colab_type": "code",
        "outputId": "61a0eaf9-4070-4603-a32f-00bf62be8d8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train['image'].shape, train['label'].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28, 1), (60000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ry1Li3o5MFhl",
        "colab_type": "code",
        "outputId": "168ba10d-ac46-4e00-e36a-153f75e433b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test['image'].shape, test['label'].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000, 28, 28, 1), (10000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "su1KzzcCJbuv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = train['image'].reshape(len(train['image']), -1)\n",
        "test_images = test['image'].reshape(len(test['image']), -1)\n",
        "\n",
        "assert train_images.ndim == 2\n",
        "assert test_images.ndim == 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeCHwMEPNK0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot_encode(x, k, dtype=np.float32):\n",
        "  \"\"\"One-hot encode x with k classes.\"\"\"\n",
        "  return np.array(x[:, None] == np.arange(k), dtype)\n",
        "\n",
        "num_classes = info.features['label'].num_classes\n",
        "\n",
        "assert num_classes == 10\n",
        "\n",
        "train_labels = one_hot_encode(train['label'], num_classes)\n",
        "test_labels = one_hot_encode(test['label'], num_classes)\n",
        "\n",
        "assert train_labels.shape[-1] == num_classes\n",
        "assert test_labels.shape[-1] == num_classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L60n4lh_nVOH",
        "colab_type": "text"
      },
      "source": [
        "# Initialize weights and bias for layers of network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdU2xztrS6My",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initalize_layer_parameters(input_units, output_units, key):\n",
        "  weight_key, bias_key = random.split(key)\n",
        "  weights = 1e-2 * random.normal(weight_key, (output_units, input_units))\n",
        "  bias = 1e-2 * random.normal(bias_key, (output_units,))\n",
        "  return weights, bias"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tazcUd8P11iu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights, bias = initalize_layer_parameters(32, 16, random.PRNGKey(0))\n",
        "assert weights.shape == (16, 32)\n",
        "assert bias.shape == (16,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Pdy5isxmVoO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_all_parameters(layer_units, key):\n",
        "  keys = random.split(key, len(layer_units))\n",
        "  return [initalize_layer_parameters(input_units, output_units, key)\n",
        "          for input_units, output_units, key in zip(layer_units[:-1], layer_units[1:], keys)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0fV0HuQ2B7k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert len(initialize_all_parameters([64, 32, 12], random.PRNGKey(0))) == 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9YZjQDTniDF",
        "colab_type": "text"
      },
      "source": [
        "# Forward pass\n",
        "\n",
        "## Define for a single image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJy5Wk-6nq4h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def relu(x):\n",
        "  return np.maximum(0, x)\n",
        "\n",
        "\n",
        "def softmax(x):\n",
        "  return x - logsumexp(x)\n",
        "\n",
        "\n",
        "def predict(parameters, image):\n",
        "  activations = image\n",
        "  activation_functions = [*[relu] * (len(parameters) - 1), softmax]\n",
        "\n",
        "  for (weights, bias), activation in zip(parameters, activation_functions):\n",
        "    outputs = np.dot(weights, activations) + bias\n",
        "    activations = activation(outputs)\n",
        "\n",
        "  return activations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IucL2CUqD0r",
        "colab_type": "code",
        "outputId": "6a80e797-2a1a-48a6-f473-1cea0720207e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "key = random.PRNGKey(52)\n",
        "image = random.normal(key, (784,))\n",
        "parameters = initialize_all_parameters([784, 512, 10], random.PRNGKey(0))\n",
        "prediction = predict(parameters, image)\n",
        "prediction.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPHkji5e5TFG",
        "colab_type": "text"
      },
      "source": [
        "## Use jax.vmap to batch `predict`\n",
        "\n",
        "`predict` won't work for a multiple images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XietKQ9oqu3-",
        "colab_type": "code",
        "outputId": "1c71dcbc-abc1-484b-9515-a66a03228f9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "images = random.normal(random.PRNGKey(0), (128, 784,))\n",
        "\n",
        "try:\n",
        "  predictions = predict(parameters, images)\n",
        "except TypeError as exception:\n",
        "  print(exception)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Incompatible shapes for dot: got (512, 784) and (128, 784).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xu8NLT9Qq5NJ",
        "colab_type": "code",
        "outputId": "3a68e003-dd4a-4563-edbc-9b69df079de6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# in_axes=(None, 0) tells jax to not map over the first argument to predict and map over the batch dim of second argument\n",
        "predict_batch = jax.vmap(predict, in_axes=(None, 0))\n",
        "predictions = predict_batch(parameters, images)\n",
        "predictions.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oLfgBhV6OQH",
        "colab_type": "text"
      },
      "source": [
        "# Training loop using `jax.grad` and `jax.jit`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1EJFLaw6Q3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(parameters, images, targets):\n",
        "  # TODO: what loss is this??\n",
        "  predictions = predict_batch(parameters, images)\n",
        "  return -np.sum(targets * predictions)\n",
        "\n",
        "def accuracy(parameters, images, targets):\n",
        "  target_class = np.argmax(targets, axis=1)\n",
        "  predicted_class = np.argmax(predict_batch(parameters, images), axis=1)\n",
        "  return np.mean(predicted_class == target_class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJy03PIJ_O1S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@jax.jit\n",
        "def update_parameters(parameters, images, targets, learning_rate):\n",
        "  gradients = jax.grad(loss)(parameters, images, targets)\n",
        "  return [(w - (learning_rate * dw), b - (learning_rate * db))\n",
        "          for (w, b), (dw, db) in zip(parameters, gradients)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lD4jE_1aMs42",
        "colab_type": "text"
      },
      "source": [
        "## Batch gradient descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRuk78JOEc1Q",
        "colab_type": "code",
        "outputId": "88e2e0c9-27bc-4b67-b9a6-6dcd7591f40b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "key = random.PRNGKey(52)\n",
        "layers = [784, 512, 256, 10]\n",
        "parameters = initialize_all_parameters(layers, key)\n",
        "epochs = 100\n",
        "learning_rate = 0.0000001\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  parameters = update_parameters(parameters, train_images, train_labels, learning_rate)\n",
        "  epoch_loss = loss(parameters, train_images, train_labels)\n",
        "  epoch_accuracy = accuracy(parameters, train_images, train_labels)\n",
        "\n",
        "  if (epoch + 1) % 10 == 0:\n",
        "    print(f\"Epoch: {epoch + 1}\\tLoss: {epoch_loss:.2E}\\t Accuracy: {epoch_accuracy:.2f}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 10\tLoss: 4.91E+04\t Accuracy: 0.82\n",
            "Epoch: 20\tLoss: 3.42E+04\t Accuracy: 0.85\n",
            "Epoch: 30\tLoss: 3.00E+04\t Accuracy: 0.84\n",
            "Epoch: 40\tLoss: 2.37E+04\t Accuracy: 0.89\n",
            "Epoch: 50\tLoss: 3.34E+04\t Accuracy: 0.81\n",
            "Epoch: 60\tLoss: 1.96E+04\t Accuracy: 0.91\n",
            "Epoch: 70\tLoss: 1.83E+04\t Accuracy: 0.91\n",
            "Epoch: 80\tLoss: 1.73E+04\t Accuracy: 0.92\n",
            "Epoch: 90\tLoss: 1.66E+04\t Accuracy: 0.92\n",
            "Epoch: 100\tLoss: 1.60E+04\t Accuracy: 0.92\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbAEmryEM2Di",
        "colab_type": "text"
      },
      "source": [
        "## Mini-batch gradient descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GUC3g8cN8A2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_training_data(batch_size=128):\n",
        "  \"\"\"Returns generator of (X, y) arrays.\"\"\"\n",
        "  # as_supervised=True returns (X, y) instead of dict\n",
        "  ds = tfds.load('mnist', batch_size=batch_size, split='train', as_supervised=True).prefetch(1)\n",
        "  return tfds.as_numpy(ds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oYzDiYTC9UJ",
        "colab_type": "code",
        "outputId": "394ee23e-a922-48a0-82d6-ce33252449b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "key = random.PRNGKey(52)\n",
        "layers = [784, 512, 256, 10]\n",
        "parameters = initialize_all_parameters(layers, key)\n",
        "epochs = 5\n",
        "learning_rate = 0.00001\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for images, labels in get_training_data():\n",
        "    images = images.reshape(len(images), -1)\n",
        "    labels = one_hot_encode(labels, num_classes)\n",
        "    parameters = update_parameters(parameters, images, labels, learning_rate)\n",
        "\n",
        "  epoch_loss = loss(parameters, train_images, train_labels)\n",
        "  epoch_train_accuracy = accuracy(parameters, train_images, train_labels)\n",
        "  epoch_test_accuracy = accuracy(parameters, test_images, test_labels)\n",
        "\n",
        "  print(f\"Epoch: {epoch + 1}\\t Loss: {epoch_loss:.2E}\\t Accuracy: {epoch_train_accuracy:.2f}\\t Test accuracy: {epoch_test_accuracy:.2f}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\t Loss: 1.61E+04\t Accuracy: 0.92\t Test accuracy: 0.92\n",
            "Epoch: 2\t Loss: 1.22E+04\t Accuracy: 0.94\t Test accuracy: 0.94\n",
            "Epoch: 3\t Loss: 9.91E+03\t Accuracy: 0.95\t Test accuracy: 0.95\n",
            "Epoch: 4\t Loss: 8.35E+03\t Accuracy: 0.96\t Test accuracy: 0.96\n",
            "Epoch: 5\t Loss: 7.21E+03\t Accuracy: 0.97\t Test accuracy: 0.96\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pa7tcW-4QArx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}